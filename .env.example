# ============================================
# LiteLLM UI 登入憑證
# ============================================
UI_USERNAME='admin'
UI_PASSWORD='your_secure_password_here'

# ============================================
# PostgreSQL 資料庫設定
# ============================================
# 注意：這些環境變數會被 docker-compose.yml 使用
POSTGRES_DB='litellm'
POSTGRES_USER='llmproxy'
POSTGRES_PASSWORD='your_secure_db_password_here'


# ============================================
# LiteLLM API 金鑰
# ============================================
# 主要 API 金鑰（用於訪問 LiteLLM proxy）
LITELLM_MASTER_KEY='sk-your-master-key-here'

# OpenRouter API 金鑰（必要）
OPENROUTER_API_KEY='your_openrouter_api_key_here'

# Gemini API 金鑰（必要）
GEMINI_API_KEY='your_gemini_api_key_here'

# ============================================
# 選用：其他 LLM 提供商 API 金鑰
# ============================================
# 如果使用 Local LM Studio 本地模型
# LM_STUDIO_API_KEY='lm-studio'
# LM_STUDIO_API_BASE='http://localhost:1234/v1'

# 使用 宿主機 本地部署的 LM Studio Docker Compose 的設定如下
LM_STUDIO_API_KEY="lm-studio"
LM_STUDIO_API_BASE="http://host.docker.internal:1234/v1"


# 如果使用 Ollama 本地模型
# OLLAMA_API_KEY='your_ollama_api_key'
# OLLAMA_API_BASE='http://localhost:11434'

# 使用 宿主機 本地部署的 Ollama Docker Docker Compose 的設定如下
OLLAMA_API_KEY='your_ollama_api_key'
OLLAMA_API_BASE='http://host.docker.internal:11434'

# ============================================
# MLflow 設定
# ============================================
# 必要設定
# MLflow 在 Docker Compose 內，使用服務名稱連接
MLFLOW_TRACKING_URI="http://mlflow:5000"
MLFLOW_EXPERIMENT_NAME="litellm-local-experiment"

# ============================================
# Nginx 設定 (選用 - 使用 nginx.conf.template 時需要)
# ============================================
# 您的域名 (例如: your-domain.synology.me)
DOMAIN_NAME='your-domain.synology.me'

# Nginx 限流設定 (每分鐘請求數)
NGINX_RATE_LIMIT='100r/m'

# 客戶端最大請求大小
CLIENT_MAX_BODY_SIZE='10M'
