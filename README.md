# LiteLLM Proxy æœå‹™

é€™æ˜¯ä¸€å€‹åŸºæ–¼ LiteLLM çš„ AI æ¨¡å‹ä»£ç†æœå‹™ï¼Œæä¾›çµ±ä¸€çš„ OpenAI ç›¸å®¹ API ä»‹é¢ä¾†è¨ªå•å¤šå€‹å¤§å‹èªè¨€æ¨¡å‹ï¼ˆLLMï¼‰æä¾›å•†ï¼Œä¸¦æ•´åˆäº† MLflow ç”¨æ–¼å¯¦é©—è¿½è¹¤å’Œ API è«‹æ±‚è¨˜éŒ„ã€‚

## åŠŸèƒ½ç‰¹è‰²

- ğŸš€ **å¤šæ¨¡å‹æ”¯æ´**ï¼šæ•´åˆ 5 å¤§ LLM æä¾›å•†ï¼ˆOpenRouterã€Google Geminiã€GitHub Modelsã€GitHub Copilotã€LM Studioï¼‰ï¼Œæ”¯æ´ 33+ ç¨®æ¨¡å‹
- ğŸ” **å®‰å…¨ç®¡ç†**ï¼šAPI é‡‘é‘°èªè­‰ã€é€Ÿç‡é™åˆ¶ã€Nginx HTTPS åå‘ä»£ç†
- ğŸ“Š **å®Œæ•´ç›£æ§**ï¼šæ•´åˆ MLflow è¿½è¹¤å¯¦é©—èˆ‡ API è«‹æ±‚è¨˜éŒ„
- ğŸ³ **å®¹å™¨åŒ–éƒ¨ç½²**ï¼šä½¿ç”¨ Docker Compose ä¸€éµå•Ÿå‹•æ‰€æœ‰æœå‹™
- ğŸ’¾ **æŒä¹…åŒ–å„²å­˜**ï¼šPostgreSQL è³‡æ–™åº«ç¢ºä¿è³‡æ–™ä¸éºå¤±
- ğŸ¯ **è³‡æºæ§åˆ¶**ï¼šé è¨­é…ç½® CPU å’Œè¨˜æ†¶é«”é™åˆ¶
- ğŸŒ **å…¬ç¶²éƒ¨ç½²**ï¼šæ”¯æ´ SSL/TLS åŠ å¯†èˆ‡ Let's Encrypt æ†‘è­‰ï¼ˆåƒè¦‹ [NGINX_SETUP.md](NGINX_SETUP.md)ï¼‰

## æ”¯æ´çš„æ¨¡å‹

æœ¬æœå‹™æ•´åˆäº†å¤šå€‹ LLM æä¾›å•†ï¼Œç¸½è¨ˆæ”¯æ´ **33+ ç¨®æ¨¡å‹**ï¼š

### ğŸŒŸ OpenRouterï¼ˆå…è²»æ¨¡å‹ï¼‰
- **OpenAI GPT-OSS-20B** - é€Ÿç‡é™åˆ¶ï¼š18 RPM

### ğŸ¤– Google Geminiï¼ˆéœ€è¦ API Keyï¼‰
- **Gemini 2.5 Pro** - 2 RPM, 125K TPM, 50 RPD
- **Gemini 2.5 Flash** - 10 RPM, 250K TPM, 250 RPD
- **Gemini 2.5 Flash Lite** - 15 RPM, 250K TPM, 1000 RPD
- **Gemini 2.0 Flash** - 15 RPM, 1M TPM, 200 RPDï¼ˆæ”¯æ´è¦–è¦ºï¼‰
- **Gemini 2.5 Flash TTS** - 3 RPM, 10K TPM, 15 RPDï¼ˆæ–‡å­—è½‰èªéŸ³ï¼‰

### ğŸ–¥ï¸ LM Studioï¼ˆæœ¬åœ°æ¨¡å‹ï¼Œç„¡é€Ÿç‡é™åˆ¶ï¼‰
- **Qwen3 Vision**: 4B, 8B, 30B
- **Qwen3 Coder**: 30B
- **Google Gemma 3**: 1B, 4B, 12B, 27B
- **OpenAI GPT-OSS-20B**

### ğŸ™ GitHub Modelsï¼ˆéœ€è¦ GitHub Tokenï¼‰
- **GPT-4o Mini** - 2 RPM
- **GPT-4.1** - 2 RPM
- **GPT-4o** - 2 RPM
- **GPT-5 Mini** - 2 RPM
- **GPT-5** - 2 RPM

### ğŸ’» GitHub Copilotï¼ˆéœ€è¦ Copilot è¨‚é–±ï¼‰
**OpenAI æ¨¡å‹ï¼š**
- **GPT-4o Mini** - 10 RPM
- **GPT-4.1** - 10 RPMï¼ˆæ”¯æ´è¦–è¦ºï¼‰
- **GPT-4o** - 10 RPMï¼ˆæ”¯æ´è¦–è¦ºï¼‰
- **GPT-5 Mini** - 10 RPMï¼ˆæ”¯æ´è¦–è¦ºï¼‰
- **GPT-5** - 10 RPMï¼ˆæ”¯æ´è¦–è¦ºï¼‰

**Anthropic æ¨¡å‹ï¼š**
- **Claude Sonnet 4.5** - 10 RPMï¼ˆæ”¯æ´è¦–è¦ºï¼‰
- **Claude Opus 4.5** - 3 RPMï¼ˆæ”¯æ´è¦–è¦ºï¼‰
- **Claude Haiku 4.5** - 10 RPMï¼ˆæ”¯æ´è¦–è¦ºï¼‰

**Google æ¨¡å‹ï¼š**
- **Gemini 3 Pro Preview** - 10 RPMï¼ˆæ”¯æ´è¦–è¦ºï¼‰
- **Gemini 3 Flash Preview** - 10 RPMï¼ˆæ”¯æ´è¦–è¦ºï¼‰
- **Gemini 2.5 Pro** - 10 RPMï¼ˆæ”¯æ´è¦–è¦ºï¼‰

**å…¶ä»–æ¨¡å‹ï¼š**
- **X.AI Grok Code Fast 1** - 10 RPM
- **Raptor Mini** - 10 RPM

> **æ³¨æ„**ï¼šRPM = æ¯åˆ†é˜è«‹æ±‚æ•¸, TPM = æ¯åˆ†é˜ Token æ•¸, RPD = æ¯æ—¥è«‹æ±‚æ•¸ã€‚è©³ç´°é…ç½®è«‹åƒè¦‹ [config.yaml](config.yaml)ã€‚

## å¿«é€Ÿé–‹å§‹

### å‰ç½®éœ€æ±‚

- Docker å’Œ Docker Compose
- è‡³å°‘ä¸€å€‹ LLM æä¾›å•†çš„ API é‡‘é‘°ï¼š
  - **OpenRouter**ï¼ˆå…è²»ï¼‰ï¼šå¾ [openrouter.ai](https://openrouter.ai) å–å¾—
  - **Google Gemini**ï¼ˆå…è²»é¡åº¦ï¼‰ï¼šå¾ [Google AI Studio](https://makersuite.google.com/app/apikey) å–å¾—
  - **GitHub Models**ï¼ˆå…è²»ï¼‰ï¼šä½¿ç”¨ GitHub Personal Access Token
  - **GitHub Copilot**ï¼ˆéœ€è¨‚é–±ï¼‰ï¼šéœ€è¦æœ‰æ•ˆçš„ Copilot è¨‚é–±
  - **LM Studio**ï¼ˆæœ¬åœ°ï¼‰ï¼šåœ¨æœ¬æ©Ÿå®‰è£ [LM Studio](https://lmstudio.ai/)

### 1. è¤‡è£½å°ˆæ¡ˆ

```bash
git clone <repository-url>
cd llm_proxy
```

### 2. è¨­å®šç’°å¢ƒè®Šæ•¸

è¤‡è£½ç’°å¢ƒè®Šæ•¸ç¯„æœ¬ä¸¦å¡«å…¥æ‚¨çš„è¨­å®šï¼š

```bash
cp .env.example .env
```

ç·¨è¼¯ `.env` æª”æ¡ˆï¼Œè¨­å®šä»¥ä¸‹æ¬„ä½ï¼š

```bash
# å¿…è¦è¨­å®š
LITELLM_MASTER_KEY='sk-your-master-key-here'

# LLM æä¾›å•† API é‡‘é‘°ï¼ˆè‡³å°‘è¨­å®šä¸€å€‹ï¼‰
OPENROUTER_API_KEY='your_openrouter_api_key_here'      # OpenRouter
GEMINI_API_KEY='your_gemini_api_key_here'              # Google Gemini
GITHUB_API_KEY='your_github_token_here'                # GitHub Models

# UI ç™»å…¥æ†‘è­‰ï¼ˆå»ºè­°ä¿®æ”¹ï¼‰
UI_USERNAME='admin'
UI_PASSWORD='your_secure_password_here'

# è³‡æ–™åº«å¯†ç¢¼ï¼ˆå»ºè­°ä¿®æ”¹ï¼‰
POSTGRES_PASSWORD='your_secure_db_password_here'

# æœ¬åœ°æ¨¡å‹ï¼ˆé¸ç”¨ï¼‰
LM_STUDIO_API_KEY='lm-studio'
LM_STUDIO_API_BASE='http://host.docker.internal:1234/v1'
```

### 3. å•Ÿå‹•æœå‹™

```bash
docker compose up -d
```

é€™å€‹æŒ‡ä»¤æœƒå•Ÿå‹•ä»¥ä¸‹æœå‹™ï¼š
- **LiteLLM Proxy**ï¼šAI æ¨¡å‹ä»£ç†æœå‹™ï¼ˆç«¯å£ 4000ï¼‰
- **PostgreSQL**ï¼šè³‡æ–™åº«æœå‹™ï¼ˆç«¯å£ 5432ï¼‰
- **MLflow**ï¼šå¯¦é©—è¿½è¹¤æœå‹™ï¼ˆç«¯å£ 5001ï¼Œåƒ…é™æœ¬æ©Ÿè¨ªå•ï¼‰
- **Nginx**ï¼šHTTPS åå‘ä»£ç†ï¼ˆç«¯å£ 443/80ï¼Œéœ€è¦ SSL æ†‘è­‰ï¼Œåƒè¦‹ [NGINX_SETUP.md](NGINX_SETUP.md)ï¼‰

### 4. è¨ªå•æœå‹™

å•Ÿå‹•æˆåŠŸå¾Œï¼Œæ‚¨å¯ä»¥é€éä»¥ä¸‹ç¶²å€è¨ªå•å„é …æœå‹™ï¼š

- **LiteLLM Proxy API**ï¼šhttp://localhost:4000
  - OpenAI ç›¸å®¹çš„ API ç«¯é»
  - å¥åº·æª¢æŸ¥ï¼šhttp://localhost:4000/health/liveliness
- **LiteLLM Web UI**ï¼šhttp://localhost:4000/ui
  - ä½¿ç”¨ `.env` ä¸­è¨­å®šçš„ `UI_USERNAME` å’Œ `UI_PASSWORD` ç™»å…¥
  - ç®¡ç†æ¨¡å‹ã€æŸ¥çœ‹ä½¿ç”¨çµ±è¨ˆ
- **MLflow Dashboard**ï¼šhttp://localhost:5001
  - æŸ¥çœ‹ API å‘¼å«è¿½è¹¤å’Œå¯¦é©—è¨˜éŒ„
  - åƒ…é™ localhost è¨ªå•ï¼ˆå®‰å…¨è€ƒé‡ï¼‰

### 5. API ä½¿ç”¨ç¯„ä¾‹

ä½¿ç”¨ OpenAI ç›¸å®¹çš„ API æ ¼å¼å‘¼å«æ¨¡å‹ï¼š

```bash
# ä½¿ç”¨ Google Gemini æ¨¡å‹
curl -X POST http://localhost:4000/v1/chat/completions \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer $LITELLM_MASTER_KEY" \
  -d '{
    "model": "google/gemini-2.5-flash",
    "messages": [
      {"role": "user", "content": "ä½ å¥½ï¼Œè«‹ä»‹ç´¹ä¸€ä¸‹ä½ è‡ªå·±"}
    ]
  }'

# ä½¿ç”¨ GitHub Copilot Claude æ¨¡å‹
curl -X POST http://localhost:4000/v1/chat/completions \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer $LITELLM_MASTER_KEY" \
  -d '{
    "model": "anthropic/claude-sonnet-4.5",
    "messages": [
      {"role": "user", "content": "Hello, introduce yourself"}
    ]
  }'

# ä½¿ç”¨æœ¬åœ° LM Studio æ¨¡å‹
curl -X POST http://localhost:4000/v1/chat/completions \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer $LITELLM_MASTER_KEY" \
  -d '{
    "model": "gemma-3-12b",
    "messages": [
      {"role": "user", "content": "What is AI?"}
    ]
  }'
```

## å¸¸ç”¨æŒ‡ä»¤

### æŸ¥çœ‹æœå‹™ç‹€æ…‹

```bash
docker compose ps
```

### æŸ¥çœ‹æœå‹™æ—¥èªŒ

```bash
# æŸ¥çœ‹æ‰€æœ‰æœå‹™æ—¥èªŒ
docker compose logs -f

# æŸ¥çœ‹ç‰¹å®šæœå‹™æ—¥èªŒ
docker compose logs -f litellm
docker compose logs -f mlflow
docker compose logs -f db
```

### åœæ­¢æœå‹™

```bash
docker compose down
```

### é‡å•Ÿæœå‹™

```bash
# é‡å•Ÿæ‰€æœ‰æœå‹™
docker compose restart

# é‡å•Ÿç‰¹å®šæœå‹™
docker compose restart litellm
```

### é‡æ–°å»ºç½®æ˜ åƒæª”

å¦‚æœä¿®æ”¹äº† Dockerfileï¼Œéœ€è¦é‡æ–°å»ºç½®ï¼š

```bash
docker compose build
docker compose up -d
```

## è³‡æºé™åˆ¶è¨­å®š

é è¨­çš„è³‡æºé™åˆ¶å¦‚ä¸‹ï¼š

| æœå‹™ | CPU é™åˆ¶ | è¨˜æ†¶é«”é™åˆ¶ | CPU ä¿ç•™ | è¨˜æ†¶é«”ä¿ç•™ |
|------|----------|-----------|---------|-----------|
| LiteLLM | 2.0 | 4G | 0.5 | 1G |
| PostgreSQL | 1.0 | 2G | 0.25 | 512M |
| MLflow | 1.0 | 2G | 0.25 | 512M |
| Nginx | 0.5 | 512M | 0.1 | 128M |

æ‚¨å¯ä»¥åœ¨ `docker-compose.yml` ä¸­èª¿æ•´é€™äº›è¨­å®šä»¥ç¬¦åˆæ‚¨çš„éœ€æ±‚ã€‚

## è³‡æ–™æŒä¹…åŒ–

ä»¥ä¸‹è³‡æ–™æœƒæŒä¹…åŒ–å„²å­˜ï¼š

- **PostgreSQL è³‡æ–™**ï¼šå„²å­˜åœ¨ `litellm_postgres_data` volumeï¼ˆLiteLLM å’Œ MLflow è³‡æ–™åº«ï¼‰
- **MLflow Artifacts**ï¼šå„²å­˜åœ¨ `mlflow_data` volumeï¼ˆå¯¦é©—è¿½è¹¤è³‡æ–™ï¼‰
- **Nginx æ—¥èªŒ**ï¼šå„²å­˜åœ¨ `nginx_logs` volumeï¼ˆè¨ªå•å’ŒéŒ¯èª¤æ—¥èªŒï¼‰
- **GitHub Copilot èªè­‰**ï¼šå„²å­˜åœ¨ `github_copilot_auth_data` volumeï¼ˆèªè­‰å¿«å–ï¼‰

å³ä½¿å®¹å™¨é‡å•Ÿï¼Œé€™äº›è³‡æ–™ä¹Ÿä¸æœƒéºå¤±ã€‚

## é€²éšè¨­å®š

### æ–°å¢è‡ªè¨‚æ¨¡å‹

ç·¨è¼¯ `config.yaml` æª”æ¡ˆï¼Œåœ¨ `model_list` ä¸­æ–°å¢æ¨¡å‹è¨­å®šï¼š

```yaml
model_list:
  - model_name: your-custom-model
    litellm_params:
      model: provider/model-name
      api_key: "os.environ/YOUR_API_KEY"
      rpm: 18
```

è¨˜å¾—åœ¨ `.env` æª”æ¡ˆä¸­æ–°å¢å°æ‡‰çš„ API é‡‘é‘°ã€‚

### ä¿®æ”¹é€Ÿç‡é™åˆ¶

åœ¨ `config.yaml` ä¸­èª¿æ•´å„æ¨¡å‹çš„ `rpm` åƒæ•¸ï¼š

```yaml
- model_name: google/gemini-2.5-flash
  litellm_params:
    model: gemini/gemini-2.5-flash
    api_key: "os.environ/GEMINI_API_KEY"
    rpm: 20  # ä¿®æ”¹ç‚ºæ‚¨éœ€è¦çš„é€Ÿç‡ï¼ˆåŸæœ¬æ˜¯ 10ï¼‰
    tpm: 500000  # åŒæ™‚ä¹Ÿå¯ä»¥èª¿æ•´ TPM
```

### PostgreSQL å¤–éƒ¨è¨ªå•

é è¨­æƒ…æ³ä¸‹ï¼ŒPostgreSQL ç«¯å£ï¼ˆ5432ï¼‰æœƒæš´éœ²åˆ°ä¸»æ©Ÿï¼Œæ–¹ä¾¿ä½¿ç”¨ DBeaverã€pgAdmin ç­‰å·¥å…·é€£æ¥ã€‚

**å¦‚æœä¸éœ€è¦å¤–éƒ¨è¨ªå•**ï¼Œå¯ä»¥åœ¨ `docker-compose.yml` ä¸­è¨»è§£æ‰é€™ä¸€è¡Œä»¥æé«˜å®‰å…¨æ€§ï¼š

```yaml
db:
  # ...
  # ports:
  #   - "5432:5432"  # è¨»è§£æ­¤è¡Œ
```

## æ•…éšœæ’é™¤

### æœå‹™ç„¡æ³•å•Ÿå‹•

1. æª¢æŸ¥ `.env` æª”æ¡ˆæ˜¯å¦æ­£ç¢ºè¨­å®š
2. ç¢ºèªç«¯å£ 4000ã€5001ã€5432 æ²’æœ‰è¢«ä½”ç”¨ï¼ˆå¦‚æœä½¿ç”¨ Nginxï¼Œé‚„éœ€è¦ 80 å’Œ 443ï¼‰
3. æŸ¥çœ‹æœå‹™æ—¥èªŒï¼š`docker compose logs -f`

### API å‘¼å«å¤±æ•—

1. æª¢æŸ¥å°æ‡‰æä¾›å•†çš„ API é‡‘é‘°æ˜¯å¦æ­£ç¢ºï¼ˆ`OPENROUTER_API_KEY`ã€`GEMINI_API_KEY`ã€`GITHUB_API_KEY` ç­‰ï¼‰
2. æª¢æŸ¥ `LITELLM_MASTER_KEY` æ˜¯å¦æ­£ç¢ºè¨­å®šåœ¨è«‹æ±‚æ¨™é ­ä¸­
3. ç¢ºèªæ¨¡å‹åç¨±æ˜¯å¦æ­£ç¢ºï¼ˆåƒè¦‹[æ”¯æ´çš„æ¨¡å‹](#æ”¯æ´çš„æ¨¡å‹)ï¼‰
4. æŸ¥çœ‹ LiteLLM æ—¥èªŒï¼š`docker compose logs -f litellm`
5. ä½¿ç”¨ `/v1/models` ç«¯é»åˆ—å‡ºæ‰€æœ‰å¯ç”¨æ¨¡å‹

### è³‡æ–™åº«é€£æ¥éŒ¯èª¤

1. ç¢ºèª PostgreSQL æœå‹™å·²å•Ÿå‹•ï¼š`docker compose ps db`
2. æª¢æŸ¥è³‡æ–™åº«å¥åº·ç‹€æ…‹ï¼š`docker compose logs db`
3. ç¢ºèª `.env` ä¸­çš„è³‡æ–™åº«æ†‘è­‰èˆ‡ `docker-compose.yml` ä¸€è‡´

### é€Ÿç‡é™åˆ¶éŒ¯èª¤

å¦‚æœé‡åˆ° 429 éŒ¯èª¤ï¼ˆToo Many Requestsï¼‰ï¼š
1. æª¢æŸ¥æ˜¯å¦è¶…éè©²æä¾›å•†çš„ API é¡åº¦é™åˆ¶ï¼ˆè©³è¦‹[æ”¯æ´çš„æ¨¡å‹](#æ”¯æ´çš„æ¨¡å‹)ï¼‰
2. é™ä½ `config.yaml` ä¸­å°æ‡‰æ¨¡å‹çš„ `rpm`/`tpm`/`rpd` è¨­å®š
3. ç­‰å¾…é€Ÿç‡é™åˆ¶é‡ç½®ï¼ˆé€šå¸¸æ˜¯ 1 åˆ†é˜ï¼‰å¾Œé‡è©¦
4. å¦‚æœä½¿ç”¨ Nginxï¼Œä¹Ÿå¯èƒ½è§¸ç™¼ IP é™æµï¼ˆé è¨­ 100 req/minï¼‰

## æ‰‹å‹•å®‰è£ï¼ˆä¸ä½¿ç”¨ Dockerï¼‰

å¦‚æœæ‚¨åå¥½æ‰‹å‹•å®‰è£è€Œéä½¿ç”¨ Dockerï¼š

### 1. å®‰è£ PostgreSQL

```bash
# å•Ÿå‹• PostgreSQL å®¹å™¨
docker run -d --name postgres-litellm \
  -e POSTGRES_DB=litellm \
  -e POSTGRES_USER=llmproxy \
  -e POSTGRES_PASSWORD=your_password \
  -p 5432:5432 \
  postgres:16
```

### 2. å®‰è£ Python ä¾è³´

```bash
# ä½¿ç”¨ uvï¼ˆæ¨è–¦ï¼‰
uv sync

# æˆ–ä½¿ç”¨ pip
pip install -e .
```

### 3. è¨­å®šè³‡æ–™åº« Schema

```bash
uv run prisma generate
uv run prisma db push
```

### 4. å•Ÿå‹• MLflow

```bash
uv run mlflow server \
  --backend-store-uri postgresql://llmproxy:your_password@localhost:5432/mlflow \
  --host 0.0.0.0 \
  --port 5001 \
  --default-artifact-root ./mlflow_artifacts
```

### 5. å•Ÿå‹• LiteLLM

```bash
# ä¸€èˆ¬æ¨¡å¼
uv run litellm --config config.yaml --port 4000

# é™¤éŒ¯æ¨¡å¼
uv run litellm --config config.yaml --port 4000 --detailed_debug
```

## æŠ€è¡“æ¶æ§‹

```
                        å…¬ç¶²è¨ªå• (é¸ç”¨)
                             â”‚
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚  Nginx (443/80)  â”‚ â—„â”€â”€â”€ SSL/TLS åŠ å¯†
                    â”‚  - Rate Limiting â”‚      HTTPS åå‘ä»£ç†
                    â”‚  - Security      â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚                                        â”‚
        â”‚            å…§ç¶²è¨ªå• (é è¨­)              â”‚
        â”‚                                        â”‚
        â–¼                                        â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  User / Application           â”‚    â”‚  LiteLLM Web UI      â”‚
â”‚  - API Clients                â”‚    â”‚  (localhost:4000/ui) â”‚
â”‚  - Python/Node.js/cURL        â”‚    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                â”‚ HTTP/HTTPS Requests
                â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚          LiteLLM Proxy Service (Port 4000)                 â”‚
â”‚  - OpenAI-compatible API (/v1/chat/completions)            â”‚
â”‚  - Multi-provider Routing (5 providers, 33+ models)        â”‚
â”‚  - Per-model Rate Limiting (RPM/TPM/RPD)                   â”‚
â”‚  - API Key Authentication                                  â”‚
â””â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â”‚                â”‚                   â”‚
    â”‚ Log Requests   â”‚ Store Metadata    â”‚ Forward API Calls
    â–¼                â–¼                   â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ MLflow   â”‚   â”‚ PostgreSQL  â”‚   â”‚  LLM Providers:         â”‚
â”‚ (5001)   â”‚   â”‚  (5432)     â”‚   â”‚  - OpenRouter           â”‚
â”‚          â”‚â—„â”€â”€â”¤  - LiteLLM  â”‚   â”‚  - Google Gemini        â”‚
â”‚ Tracking â”‚   â”‚  - MLflow   â”‚   â”‚  - GitHub Models        â”‚
â”‚ Server   â”‚   â”‚             â”‚   â”‚  - GitHub Copilot       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚  - LM Studio (æœ¬åœ°)      â”‚
                                 â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

æŒä¹…åŒ–å„²å­˜ (Docker Volumes):
  - postgres_data: è³‡æ–™åº«è³‡æ–™
  - mlflow_data: MLflow artifacts
  - nginx_logs: Nginx æ—¥èªŒ
  - github_copilot_auth_data: Copilot èªè­‰å¿«å–
```

## æˆæ¬Š

è«‹åƒé–±å°ˆæ¡ˆçš„ LICENSE æª”æ¡ˆã€‚

## æ”¯æ´

å¦‚æœ‰å•é¡Œæˆ–éœ€è¦å”åŠ©ï¼Œè«‹æäº¤ Issue æˆ– Pull Requestã€‚

## é‡å»º docker æ˜ åƒæª”
å¦‚æœéœ€è¦é‡å»º Docker æ˜ åƒæª”ï¼Œå¯ä»¥ä½¿ç”¨ä»¥ä¸‹æŒ‡ä»¤ï¼š

```bash
docker compose down
docker compose build --no-cache
docker compose up -d
```
é€™å°‡æœƒå¿½ç•¥å¿«å–ï¼Œé‡æ–°å»ºç½®æ‰€æœ‰æœå‹™çš„æ˜ åƒæª”ã€‚
é€™å°‡æœƒåœæ­¢ç›®å‰çš„æœå‹™ï¼Œé‡æ–°å»ºç½®æ˜ åƒæª”ï¼Œä¸¦ä»¥åˆ†é›¢æ¨¡å¼å•Ÿå‹•æœå‹™ã€‚