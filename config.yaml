model_list:
  - model_name: gpt-oss-20b
    litellm_params:
      model: openrouter/openai/gpt-oss-20b:free
      api_key: "os.environ/OPENROUTER_API_KEY"
      rpm: 18  # OpenRouter 免費模型限制是 20 RPM,留緩衝設 18
  - model_name: gemini-2.5-pro
    litellm_params:
      model: gemini/gemini-2.5-pro
      api_key: "os.environ/GEMINI_API_KEY"
      rpm: 2
      tpm: 125000
      rpd: 50
  - model_name: gemini-2.5-flash
    litellm_params:
      model: gemini/gemini-2.5-flash
      api_key: "os.environ/GEMINI_API_KEY"
      rpm: 10
      tpm: 250000
      rpd: 250
  - model_name: gemini-2.5-flash-lite
    litellm_params:
      model: gemini/gemini-2.5-flash-lite
      api_key: "os.environ/GEMINI_API_KEY"
      rpm: 15
      tpm: 250000
      rpd: 1000
  - model_name: gemini-2.0-flash
    litellm_params:
      model: gemini/gemini-2.0-flash
      api_key: "os.environ/GEMINI_API_KEY"
      rpm: 15
      tpm: 1000000
      rpd: 200
  - model_name: gemini-2.5-flash-tts
    litellm_params:
      model: gemini/gemini-2.5-flash-tts
      api_key: "os.environ/GEMINI_API_KEY"
      rpm: 3
      tpm: 10000
      rpd: 15
  - model_name: gemini-robotics-er-1.5-preview
    litellm_params:
      model: gemini/gemini-robotics-er-1.5-preview
      api_key: "os.environ/GEMINI_API_KEY"
      rpm: 10
      tpm: 250000
      rpd: 250
  - model_name: qwen3-vl-4b
    litellm_params:
      model: lm_studio/qwen/qwen3-vl-4b
  - model_name: qwen3-vl-8b
    litellm_params:
      model: lm_studio/qwen/qwen3-vl-8b
  - model_name: qwen3-vl-30b
    litellm_params:
      model: lm_studio/qwen/qwen3-vl-30b
  - model_name: qwen3-coder-30b
    litellm_params:
      model: lm_studio/qwen/qwen3-coder-30b
  - model_name: gemma-3-1b
    litellm_params:
      model: lm_studio/google/gemma-3-1b
  - model_name: gemma-3-4b
    litellm_params:
      model: lm_studio/google/gemma-3-4b
  - model_name: gemma-3-12b
    litellm_params:
      model: lm_studio/google/gemma-3-12b
  - model_name: gemma-3-27b
    litellm_params:
      model: lm_studio/google/gemma-3-27b
  - model_name: gpt-oss-20b-local
    litellm_params:
      model: lm_studio/openai/gpt-oss-20b
  - model_name: glm-4.6v-flash
    litellm_params:
      model: lm_studio/zai-org/glm-4.6v-flash
  - model_name: ministral-3-14b-reasoning
    litellm_params:
      model: lm_studio/mistralai/ministral-3-14b-reasoning
  - model_name: deepseek-ai/deepseek-r1-distill-qwen-7b
    litellm_params:
      model: nvidia_nim/deepseek-ai/deepseek-r1-distill-qwen-7b
      api_key: "os.environ/NVIDIA_NIM_API_KEY"
  - model_name: deepseek-ai/deepseek-v3.2
    litellm_params:
      model: nvidia_nim/deepseek-ai/deepseek-v3.2
      api_key: "os.environ/NVIDIA_NIM_API_KEY"
  - model_name: github-Llama-3.2-11B-Vision-Instruct
    litellm_params:
      model: github/Llama-3.2-11B-Vision-Instruct
      api_key: "os.environ/GITHUB_API_KEY"
  - model_name: gpt-4o-mini
    litellm_params:
      model: github_copilot/gpt-4o-mini-2024-07-18
      rpm: 20
      extra_headers:
        editor-version: "vscode/1.85.1"
        editor-plugin-version: "copilot/1.155.0"
        Copilot-Integration-Id: "vscode-chat"
        user-agent: "GithubCopilot/1.155.0"
  - model_name: gpt-4.1
    litellm_params:
      model: github_copilot/gpt-4.1-2025-04-14
      rpm: 20
      extra_headers:
        editor-version: "vscode/1.85.1"
        editor-plugin-version: "copilot/1.155.0"
        Copilot-Integration-Id: "vscode-chat"
        user-agent: "GithubCopilot/1.155.0"
        Copilot-Vision-Request: "true"
  - model_name: gpt-4o
    litellm_params:
      model: github_copilot/gpt-4o-2024-11-20
      rpm: 20
      extra_headers:
        editor-version: "vscode/1.85.1"
        editor-plugin-version: "copilot/1.155.0"
        Copilot-Integration-Id: "vscode-chat"
        user-agent: "GithubCopilot/1.155.0"
        Copilot-Vision-Request: "true"
  - model_name: gpt-5-mini
    litellm_params:
      model: github_copilot/gpt-5-mini
      rpm: 20
      extra_headers:
        editor-version: "vscode/1.85.1"
        editor-plugin-version: "copilot/1.155.0"
        Copilot-Integration-Id: "vscode-chat"
        user-agent: "GithubCopilot/1.155.0"
        Copilot-Vision-Request: "true"
  - model_name: grok-code-fast
    litellm_params:
      model: github_copilot/grok-code-fast-1
      rpm: 20
      extra_headers:
        editor-version: "vscode/1.85.1"
        editor-plugin-version: "copilot/1.155.0"
        Copilot-Integration-Id: "vscode-chat"
        user-agent: "GithubCopilot/1.155.0"
  - model_name: raptor-mini
    litellm_params:
      model: github_copilot/raptor-mini
      rpm: 20
      extra_headers:
        editor-version: "vscode/1.85.1"
        editor-plugin-version: "copilot/1.155.0"
        Copilot-Integration-Id: "vscode-chat"
        user-agent: "GithubCopilot/1.155.0"

litellm_settings:
  drop_params: true
  success_callback: ["mlflow"]
  failure_callback: ["mlflow"]

general_settings:
  master_key: "os.environ/LITELLM_MASTER_KEY"